{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cls_nnetwork' from './classes/cls_nnetwork.py'>"
      ]
     },
     "execution_count": 1100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, \"./classes/\")\n",
    "import cls_nnetwork\n",
    "\n",
    "# reloading functions without runtime.restart\n",
    "import importlib\n",
    "importlib.reload(cls_nnetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> train-test inited:  {'y_test_cut': True, 'X_test_cut': True, 'y_train_cut': True, 'X_train_cut': True}\n"
     ]
    }
   ],
   "source": [
    "# cut -- train test data with trimmed columns, so that it's more easy to train\n",
    "\n",
    "nn_manager_cut = cls_nnetwork.NeuralManager(dir_path='../data/csv_to_train/train_test_cut/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nn_manager_cut.X_train = nn_manager_cut.X_train[['Open', 'Vol']]\n",
    "# nn_manager_cut.X_test = nn_manager_cut.X_test[['Open', 'Vol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_manager_cut.X_train.drop[columns=['Open', ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.52988659e+00,  4.78975360e+00,  4.74139303e+00,\n",
       "         1.74639067e+02,  1.29200649e+00,  1.87564906e+00,\n",
       "         1.23854073e-01,  3.30862295e+00, -4.16368286e-01,\n",
       "        -4.19170152e+02,  2.96856492e+00,  1.36703957e+00],\n",
       "       [ 3.81150200e+00,  4.42010246e+00,  4.03002493e+00,\n",
       "         1.86548731e+02,  1.24667529e+00,  1.87347194e+00,\n",
       "         1.72651774e+00,  2.53817428e+00, -2.38363171e-01,\n",
       "        -3.08142681e+01,  3.56691540e+00,  1.54784809e+00]])"
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "nn_manager_cut.normalize_X(scaler=RobustScaler)\n",
    "\n",
    "nn_manager_cut.X_train_normalized[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolling data to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 4\n",
    "nn_manager_cut.unroll_X_to_sequences(sequence_len=sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.53689240e+01,  3.51928763e+01,  3.72144714e+01,\n",
       "         6.43691996e-01,  8.78219500e-01,  3.22867247e+00,\n",
       "         4.83528350e-01, -2.62732657e-02, -3.42710997e-01,\n",
       "        -1.29561296e-01,  2.21669940e+00,  6.36455909e-01],\n",
       "       [ 3.66991727e+01,  3.66113686e+01,  3.65890404e+01,\n",
       "         7.00706344e-01,  1.06493891e+00,  3.22761248e+00,\n",
       "        -2.85041974e-01,  1.70764865e-01, -3.42710997e-01,\n",
       "        -1.29561296e-01,  2.21669940e+00,  6.36455909e-01],\n",
       "       [ 3.90631428e+01,  3.79461332e+01,  3.74674023e+01,\n",
       "         1.03303665e+00,  1.34978675e+00,  3.22633882e+00,\n",
       "        -8.60041445e-02,  5.25127690e-01, -3.41687980e-01,\n",
       "        -8.42312423e-01,  1.90828686e+00,  8.10769348e-01],\n",
       "       [ 3.74178590e+01,  3.81480361e+01,  3.90945838e+01,\n",
       "         7.63548826e-01,  1.35460228e+00,  3.22495080e+00,\n",
       "         6.05842104e-02,  7.35483801e-01, -3.57033248e-01,\n",
       "         7.15703157e-01,  3.41691933e+00,  9.04069166e-01]])"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_test_unrolled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.66991727e+01,  3.66113686e+01,  3.65890404e+01,\n",
       "         7.00706344e-01,  1.06493891e+00,  3.22761248e+00,\n",
       "        -2.85041974e-01,  1.70764865e-01, -3.42710997e-01,\n",
       "        -1.29561296e-01,  2.21669940e+00,  6.36455909e-01],\n",
       "       [ 3.90631428e+01,  3.79461332e+01,  3.74674023e+01,\n",
       "         1.03303665e+00,  1.34978675e+00,  3.22633882e+00,\n",
       "        -8.60041445e-02,  5.25127690e-01, -3.41687980e-01,\n",
       "        -8.42312423e-01,  1.90828686e+00,  8.10769348e-01],\n",
       "       [ 3.74178590e+01,  3.81480361e+01,  3.90945838e+01,\n",
       "         7.63548826e-01,  1.35460228e+00,  3.22495080e+00,\n",
       "         6.05842104e-02,  7.35483801e-01, -3.57033248e-01,\n",
       "         7.15703157e-01,  3.41691933e+00,  9.04069166e-01],\n",
       "       [ 3.65447733e+01,  3.69161259e+01,  3.78081799e+01,\n",
       "         6.42551709e-01,  1.35107044e+00,  3.22358723e+00,\n",
       "         7.93558608e-03,  7.70429879e-01, -3.59079284e-01,\n",
       "         3.31283313e-01,  6.84514963e+00,  8.84127896e-01]])"
      ]
     },
     "execution_count": 1107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# goes up by one sequence -- compare this cell result vs previous\n",
    "nn_manager_cut.X_test_unrolled[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[n_seq-n_steps in MLM example elaboration](z_MlMastery%20LSTM%20for%20TS%20.ipynb#n_seq-n_steps)<br>\n",
    "(We can parameterize this and define the number of subsequences as n_seq and the number of time steps per subsequence as n_steps. [[source]](https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/#:~:text=We%20can%20parameterize%20this%20and))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_rows': 3178, 'n_seq': 2, 'n_steps_subseq': 2, 'n_features': 12},\n",
       " {'n_rows': 791, 'n_seq': 2, 'n_steps_subseq': 2, 'n_features': 12})"
      ]
     },
     "execution_count": 1109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Dense\n",
    "from tensorflow.keras.initializers import GlorotUniform, GlorotNormal\n",
    "\n",
    "n_steps_subseq = 2\n",
    "n_seq = 2\n",
    "n_features = nn_manager_cut.X_train.shape[1]\n",
    "\n",
    "# CNN-LSTM\n",
    "shape_cnn_lstm_train = dict(\n",
    "            n_rows=nn_manager_cut.X_train_unrolled.shape[0], \n",
    "            n_seq=n_seq, \n",
    "            n_steps_subseq=n_steps_subseq, \n",
    "            n_features=n_features)\n",
    "\n",
    "shape_cnn_lstm_test = {key:(value if key != 'n_rows' else nn_manager_cut.X_test_unrolled.shape[0]) \n",
    "                       for (key, value) in shape_cnn_lstm_train.items()}\n",
    "(shape_cnn_lstm_train, shape_cnn_lstm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM shape\n",
    "[[#Setting seq len for X_* unrolling]](#Unrolling-data-to-sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_rows': 3178, 'n_seq': 8, 'n_features': 12},\n",
       " {'n_rows': 791, 'n_seq': 8, 'n_features': 12})"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacked LSTM \n",
    "shape_lstm_stacked_train = dict(\n",
    "            n_rows=nn_manager_cut.X_train_unrolled.shape[0], \n",
    "            n_seq=sequence_len, \n",
    "            n_features=n_features) # not splitting to subseq\n",
    "\n",
    "shape_lstm_stacked_test = {key:(value if key != 'n_rows' else nn_manager_cut.X_test_unrolled.shape[0]) \n",
    "                       for (key, value) in shape_lstm_stacked_train.items()}\n",
    "\n",
    "(shape_lstm_stacked_train, shape_lstm_stacked_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-LSTM Architecture\n",
    "\n",
    "weights_init = GlorotNormal()\n",
    "\n",
    "conv1D_0 = Conv1D(filters=64, kernel_size=1, activation='relu', padding='same', kernel_initializer=weights_init)\n",
    "conv1D_1 = Conv1D(filters=64, kernel_size=1, activation='relu', padding='same')\n",
    "# conv1D_2 = Conv1D(filters=64, kernel_size=1, activation='relu', padding='causal')\n",
    "# conv1D_3 = Conv1D(filters=64, kernel_size=1, activation='relu', padding='causal')\n",
    "\n",
    "# src: \n",
    "# https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/#:~:text=A%20convolutional%20neural\n",
    "template_CNN_LSTM = [\n",
    "    TimeDistributed(conv1D_0, input_shape=(None, shape_cnn_lstm_train['n_steps_subseq'], shape_cnn_lstm_train['n_features'])),\n",
    "    TimeDistributed(conv1D_1),\n",
    "#     TimeDistributed(conv1D_2),\n",
    "#     TimeDistributed(conv1D_3),\n",
    "    TimeDistributed(MaxPooling1D(pool_size=2)),\n",
    "    TimeDistributed(Flatten()),\n",
    "    LSTM(50, activation='relu', return_sequences = True),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(50),\n",
    "    Dense(20),\n",
    "    Dense(1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked LSTM\n",
    "[[to #Model-fit]](#Model-fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked LSTM\n",
    "\n",
    "weights_init = GlorotNormal()\n",
    "\n",
    "template_Stacked_LSTM = [\n",
    "    LSTM(50, activation='relu', \n",
    "         input_shape=(shape_lstm_stacked_train['n_seq'], shape_lstm_stacked_train['n_features']),\n",
    "         return_sequences=True, kernel_initializer=weights_init),\n",
    "    LSTM(50, activation='relu'),    \n",
    "    Dense(1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3178, 4, 12)"
      ]
     },
     "execution_count": 1113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_train_unrolled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Model with the chosen Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> model compiled\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_158 (LSTM)              (None, 8, 50)             12600     \n",
      "_________________________________________________________________\n",
      "lstm_159 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 32,851\n",
      "Trainable params: 32,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assembling and compiling model\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "opt_adam = keras.optimizers.Adam(\n",
    "    learning_rate=5e-5,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False, \n",
    ")\n",
    "\n",
    "training_params = dict(optimizer=opt_adam, loss='mean_absolute_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "nn_manager_cut.model_combine(template=template_Stacked_LSTM, compile_dict=training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3178, 2, 2, 12), (791, 2, 2, 12))"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN-LSTMs DataShapes\n",
    "data_shape_cnn_lstm_train = (\n",
    "    shape_cnn_lstm_train['n_rows'], \n",
    "    shape_cnn_lstm_train['n_seq'], \n",
    "    shape_cnn_lstm_train['n_steps_subseq'],\n",
    "    shape_cnn_lstm_train['n_features']\n",
    ")\n",
    "data_shape_cnn_lstm_test = (\n",
    "    shape_cnn_lstm_test['n_rows'], \n",
    "    shape_cnn_lstm_test['n_seq'], \n",
    "    shape_cnn_lstm_test['n_steps_subseq'],\n",
    "    shape_cnn_lstm_test['n_features']\n",
    ")\n",
    "(data_shape_cnn_lstm_train, data_shape_cnn_lstm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3178, 8, 12), (791, 8, 12))"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTMs Stacked DataShapes\n",
    "data_shape_lstm_stacked_train = (\n",
    "    shape_lstm_stacked_train['n_rows'], \n",
    "    shape_lstm_stacked_train['n_seq'],\n",
    "    shape_cnn_lstm_train['n_features']\n",
    ")\n",
    "data_shape_lstm_stacked_test = (\n",
    "    shape_cnn_lstm_test['n_rows'], \n",
    "    shape_lstm_stacked_train['n_seq'],\n",
    "    shape_cnn_lstm_test['n_features']\n",
    ")\n",
    "(data_shape_lstm_stacked_train, data_shape_lstm_stacked_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 152544 into shape (3178,8,12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1117-55464b074bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                            \u001b[0mreturn_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                            \u001b[0mprint_charts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                            \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                         )\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~tf/train/classes/cls_nnetwork.py\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(self, data_shape_train, data_shape_test, n_epoch, batch_size, verbose, early_stopping, print_charts, use_tensorboard, return_results)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_unrolled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train_unrolled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_shape_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test_unrolled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 152544 into shape (3178,8,12)"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "nn_manager_cut.model_fit(n_epoch=150,\n",
    "                           data_shape_train=data_shape_lstm_stacked_train,\n",
    "                           data_shape_test=data_shape_lstm_stacked_test,\n",
    "                           verbose=0, \n",
    "                           return_results=True, \n",
    "                           print_charts=True,\n",
    "                           early_stopping=True\n",
    "                        )\n",
    "plt.ylim(0,1e3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architectures: <br>\n",
    "[[#Stacked-LSTM]](#Stacked-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model with changed time frames\n",
    "one of the possible reasons for the poor loss is that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sh = nn_manager_cut.X_test_unrolled[1].shape\n",
    "\n",
    "# X_pred = nn_manager_cut.X_test_unrolled[1].reshape(int(sh[0]/n_steps_subseq), n_steps_subseq, n_features)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
