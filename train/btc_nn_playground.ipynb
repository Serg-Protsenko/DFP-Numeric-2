{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cls_nnetwork' from './classes/cls_nnetwork.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, \"./classes/\")\n",
    "import cls_nnetwork\n",
    "\n",
    "# reloading functions without runtime.restart\n",
    "import importlib\n",
    "importlib.reload(cls_nnetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> train-test inited:  {'X_test_cut': True, 'X_train_cut': True, 'y_test_cut': True, 'y_train_cut': True}\n"
     ]
    }
   ],
   "source": [
    "# cut -- train test data with trimmed columns, so that it's more easy to train\n",
    "\n",
    "nn_manager_cut = cls_nnetwork.NeuralManager(dir_path='../data/csv_to_train/train_test_cut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3182, 12), (795, 12))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_train.shape, nn_manager_cut.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Vol</th>\n",
       "      <th>AVBLS</th>\n",
       "      <th>NTRAT</th>\n",
       "      <th>TOUTV</th>\n",
       "      <th>TRFEE</th>\n",
       "      <th>BTC_MINED_PDAY</th>\n",
       "      <th>VOL_CHANGE_PDAY</th>\n",
       "      <th>MWNUS_CH_PDAY</th>\n",
       "      <th>NTRAT_CH_PDAY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-03</th>\n",
       "      <td>4859.3</td>\n",
       "      <td>5278.4</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>13830000.0</td>\n",
       "      <td>1.248330</td>\n",
       "      <td>397961949.0</td>\n",
       "      <td>1.306792e+06</td>\n",
       "      <td>142.102988</td>\n",
       "      <td>425.0</td>\n",
       "      <td>-12780000.0</td>\n",
       "      <td>52351.0</td>\n",
       "      <td>360333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-02</th>\n",
       "      <td>4145.1</td>\n",
       "      <td>4899.6</td>\n",
       "      <td>4143.5</td>\n",
       "      <td>14770000.0</td>\n",
       "      <td>1.215507</td>\n",
       "      <td>397560778.0</td>\n",
       "      <td>3.429199e+06</td>\n",
       "      <td>114.489789</td>\n",
       "      <td>1512.5</td>\n",
       "      <td>-940000.0</td>\n",
       "      <td>61873.0</td>\n",
       "      <td>401171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>4102.3</td>\n",
       "      <td>4159.1</td>\n",
       "      <td>4076.8</td>\n",
       "      <td>3220000.0</td>\n",
       "      <td>1.205358</td>\n",
       "      <td>397191600.0</td>\n",
       "      <td>1.744093e+06</td>\n",
       "      <td>61.846737</td>\n",
       "      <td>2162.5</td>\n",
       "      <td>11550000.0</td>\n",
       "      <td>87465.0</td>\n",
       "      <td>369178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>4111.8</td>\n",
       "      <td>4121.9</td>\n",
       "      <td>4082.2</td>\n",
       "      <td>2430000.0</td>\n",
       "      <td>1.173566</td>\n",
       "      <td>396808790.0</td>\n",
       "      <td>9.168389e+05</td>\n",
       "      <td>44.614255</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>790000.0</td>\n",
       "      <td>34688.0</td>\n",
       "      <td>382810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-30</th>\n",
       "      <td>4103.7</td>\n",
       "      <td>4138.1</td>\n",
       "      <td>4057.1</td>\n",
       "      <td>2550000.0</td>\n",
       "      <td>1.204920</td>\n",
       "      <td>396430531.0</td>\n",
       "      <td>9.228557e+05</td>\n",
       "      <td>54.673729</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>-120000.0</td>\n",
       "      <td>64109.0</td>\n",
       "      <td>378259.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low         Vol     AVBLS        NTRAT  \\\n",
       "Date                                                                    \n",
       "2019-04-03  4859.3  5278.4  4814.0  13830000.0  1.248330  397961949.0   \n",
       "2019-04-02  4145.1  4899.6  4143.5  14770000.0  1.215507  397560778.0   \n",
       "2019-04-01  4102.3  4159.1  4076.8   3220000.0  1.205358  397191600.0   \n",
       "2019-03-31  4111.8  4121.9  4082.2   2430000.0  1.173566  396808790.0   \n",
       "2019-03-30  4103.7  4138.1  4057.1   2550000.0  1.204920  396430531.0   \n",
       "\n",
       "                   TOUTV       TRFEE  BTC_MINED_PDAY  VOL_CHANGE_PDAY  \\\n",
       "Date                                                                    \n",
       "2019-04-03  1.306792e+06  142.102988           425.0      -12780000.0   \n",
       "2019-04-02  3.429199e+06  114.489789          1512.5        -940000.0   \n",
       "2019-04-01  1.744093e+06   61.846737          2162.5       11550000.0   \n",
       "2019-03-31  9.168389e+05   44.614255          1425.0         790000.0   \n",
       "2019-03-30  9.228557e+05   54.673729          2050.0        -120000.0   \n",
       "\n",
       "            MWNUS_CH_PDAY  NTRAT_CH_PDAY  \n",
       "Date                                      \n",
       "2019-04-03        52351.0       360333.0  \n",
       "2019-04-02        61873.0       401171.0  \n",
       "2019-04-01        87465.0       369178.0  \n",
       "2019-03-31        34688.0       382810.0  \n",
       "2019-03-30        64109.0       378259.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.52988659e+00,  4.78975360e+00,  4.74139303e+00,\n",
       "         1.74639067e+02,  1.29200649e+00,  1.87564906e+00,\n",
       "         1.23854073e-01,  3.30862295e+00, -4.16368286e-01,\n",
       "        -4.19170152e+02,  2.96856492e+00,  1.36703957e+00],\n",
       "       [ 3.81150200e+00,  4.42010246e+00,  4.03002493e+00,\n",
       "         1.86548731e+02,  1.24667529e+00,  1.87347194e+00,\n",
       "         1.72651774e+00,  2.53817428e+00, -2.38363171e-01,\n",
       "        -3.08142681e+01,  3.56691540e+00,  1.54784809e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "nn_manager_cut.normalize_X(scaler=RobustScaler)\n",
    "\n",
    "nn_manager_cut.X_train_normalized[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_manager_cut.split_X_to_sequencees(sequence_len=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.53689240e+01,  3.51928763e+01,  3.72144714e+01,\n",
       "         6.43691996e-01,  8.78219500e-01,  3.22867247e+00,\n",
       "         4.83528350e-01, -2.62732657e-02, -3.42710997e-01,\n",
       "        -1.29561296e-01,  2.21669940e+00,  6.36455909e-01],\n",
       "       [ 3.66991727e+01,  3.66113686e+01,  3.65890404e+01,\n",
       "         7.00706344e-01,  1.06493891e+00,  3.22761248e+00,\n",
       "        -2.85041974e-01,  1.70764865e-01, -3.42710997e-01,\n",
       "        -1.29561296e-01,  2.21669940e+00,  6.36455909e-01],\n",
       "       [ 3.90631428e+01,  3.79461332e+01,  3.74674023e+01,\n",
       "         1.03303665e+00,  1.34978675e+00,  3.22633882e+00,\n",
       "        -8.60041445e-02,  5.25127690e-01, -3.41687980e-01,\n",
       "        -8.42312423e-01,  1.90828686e+00,  8.10769348e-01],\n",
       "       [ 3.74178590e+01,  3.81480361e+01,  3.90945838e+01,\n",
       "         7.63548826e-01,  1.35460228e+00,  3.22495080e+00,\n",
       "         6.05842104e-02,  7.35483801e-01, -3.57033248e-01,\n",
       "         7.15703157e-01,  3.41691933e+00,  9.04069166e-01],\n",
       "       [ 3.65447733e+01,  3.69161259e+01,  3.78081799e+01,\n",
       "         6.42551709e-01,  1.35107044e+00,  3.22358723e+00,\n",
       "         7.93558608e-03,  7.70429879e-01, -3.59079284e-01,\n",
       "         3.31283313e-01,  6.84514963e+00,  8.84127896e-01],\n",
       "       [ 3.71549275e+01,  3.65749695e+01,  3.75552491e+01,\n",
       "         8.52744607e-01,  1.45403566e+00,  3.22232084e+00,\n",
       "         2.62907210e-01,  6.62815003e-01, -2.87468031e-01,\n",
       "        -5.26117261e-01, -3.21105962e-01,  8.04836555e-01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_test_unrolled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.66991727e+01,  3.66113686e+01,  3.65890404e+01,\n",
       "         7.00706344e-01,  1.06493891e+00,  3.22761248e+00,\n",
       "        -2.85041974e-01,  1.70764865e-01, -3.42710997e-01,\n",
       "        -1.29561296e-01,  2.21669940e+00,  6.36455909e-01],\n",
       "       [ 3.90631428e+01,  3.79461332e+01,  3.74674023e+01,\n",
       "         1.03303665e+00,  1.34978675e+00,  3.22633882e+00,\n",
       "        -8.60041445e-02,  5.25127690e-01, -3.41687980e-01,\n",
       "        -8.42312423e-01,  1.90828686e+00,  8.10769348e-01],\n",
       "       [ 3.74178590e+01,  3.81480361e+01,  3.90945838e+01,\n",
       "         7.63548826e-01,  1.35460228e+00,  3.22495080e+00,\n",
       "         6.05842104e-02,  7.35483801e-01, -3.57033248e-01,\n",
       "         7.15703157e-01,  3.41691933e+00,  9.04069166e-01],\n",
       "       [ 3.65447733e+01,  3.69161259e+01,  3.78081799e+01,\n",
       "         6.42551709e-01,  1.35107044e+00,  3.22358723e+00,\n",
       "         7.93558608e-03,  7.70429879e-01, -3.59079284e-01,\n",
       "         3.31283313e-01,  6.84514963e+00,  8.84127896e-01],\n",
       "       [ 3.71549275e+01,  3.65749695e+01,  3.75552491e+01,\n",
       "         8.52744607e-01,  1.45403566e+00,  3.22232084e+00,\n",
       "         2.62907210e-01,  6.62815003e-01, -2.87468031e-01,\n",
       "        -5.26117261e-01, -3.21105962e-01,  8.04836555e-01],\n",
       "       [ 3.54949581e+01,  3.62142962e+01,  3.59325235e+01,\n",
       "         1.08358937e+00,  1.55763891e+00,  3.22108606e+00,\n",
       "        -1.22351362e-02,  6.12889716e-01, -3.39641944e-01,\n",
       "        -5.79581796e-01, -3.21105962e-01,  7.79051041e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# goes up by one sequence\n",
    "nn_manager_cut.X_test_unrolled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3176, 6, 12), 228672)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = nn_manager_cut.X_train_unrolled.shape\n",
    "shape, shape[0]*shape[1]*shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[n_seq-n_steps in MLM example elaboration](z_MlMastery%20LSTM%20for%20TS%20.ipynb#n_seq-n_steps)<br>\n",
    "(We can parameterize this and define the number of subsequences as n_seq and the number of time steps per subsequence as n_steps. [[source]](https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/#:~:text=We%20can%20parameterize%20this%20and))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed \n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Dense\n",
    "\n",
    "n_steps_subseq = 2\n",
    "n_seq = 3\n",
    "n_features = nn_manager_cut.X_train.shape[1]\n",
    "\n",
    "conv1D_params = dict(filters=64, kernel_size=1, activation='relu')\n",
    "\n",
    "# src: \n",
    "# https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/#:~:text=A%20convolutional%20neural\n",
    "template = [\n",
    "    TimeDistributed(Conv1D(**conv1D_params), input_shape=(None, n_steps_subseq, n_features)),\n",
    "    TimeDistributed(MaxPooling1D(pool_size=2)),\n",
    "    TimeDistributed(Flatten()),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> model compiled\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_9 (TimeDist (None, None, 2, 64)       832       \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, None, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                23000     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 23,883\n",
      "Trainable params: 23,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.model_combine(template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 - 1s - loss: 42721.1836 - mae: 68.1942 - val_loss: 1465678.0000 - val_mae: 758.4510\n",
      "Epoch 2/30\n",
      "100/100 - 1s - loss: 44598.9336 - mae: 71.4382 - val_loss: 1505349.8750 - val_mae: 666.6133\n",
      "Epoch 3/30\n",
      "100/100 - 1s - loss: 48321.4141 - mae: 74.9026 - val_loss: 2582349.0000 - val_mae: 852.2178\n",
      "Epoch 4/30\n",
      "100/100 - 1s - loss: 46196.6289 - mae: 71.7087 - val_loss: 2935627.2500 - val_mae: 921.4590\n",
      "Epoch 5/30\n",
      "100/100 - 1s - loss: 49100.7461 - mae: 76.4067 - val_loss: 2161624.2500 - val_mae: 773.0225\n",
      "Epoch 6/30\n",
      "100/100 - 1s - loss: 45470.6914 - mae: 71.2923 - val_loss: 1607973.3750 - val_mae: 692.7996\n",
      "Epoch 7/30\n",
      "100/100 - 1s - loss: 42962.1914 - mae: 67.7803 - val_loss: 1532980.6250 - val_mae: 661.9849\n",
      "Epoch 8/30\n",
      "100/100 - 1s - loss: 41973.0195 - mae: 67.2338 - val_loss: 1910113.5000 - val_mae: 734.7144\n",
      "Epoch 9/30\n",
      "100/100 - 1s - loss: 42903.0312 - mae: 69.4423 - val_loss: 1833224.2500 - val_mae: 721.7490\n",
      "Epoch 10/30\n",
      "100/100 - 1s - loss: 42633.8828 - mae: 67.5181 - val_loss: 1430895.0000 - val_mae: 657.4177\n",
      "Epoch 11/30\n",
      "100/100 - 1s - loss: 41394.1445 - mae: 65.9595 - val_loss: 1432780.3750 - val_mae: 640.1188\n",
      "Epoch 12/30\n",
      "100/100 - 1s - loss: 42114.8008 - mae: 66.7307 - val_loss: 1495171.7500 - val_mae: 657.4929\n",
      "Epoch 13/30\n",
      "100/100 - 1s - loss: 40890.5078 - mae: 65.9700 - val_loss: 1356876.1250 - val_mae: 647.5475\n",
      "Epoch 14/30\n",
      "100/100 - 1s - loss: 42105.7461 - mae: 66.7685 - val_loss: 1435877.2500 - val_mae: 650.9447\n",
      "Epoch 15/30\n",
      "100/100 - 1s - loss: 42493.1953 - mae: 68.1899 - val_loss: 1507295.8750 - val_mae: 666.8148\n",
      "Epoch 16/30\n",
      "100/100 - 1s - loss: 44766.8164 - mae: 69.8532 - val_loss: 1755724.6250 - val_mae: 721.3535\n",
      "Epoch 17/30\n",
      "100/100 - 1s - loss: 43726.3789 - mae: 69.8693 - val_loss: 1429501.6250 - val_mae: 676.8192\n",
      "Epoch 18/30\n",
      "100/100 - 1s - loss: 43968.1250 - mae: 68.3927 - val_loss: 1717807.0000 - val_mae: 699.5843\n",
      "Epoch 19/30\n",
      "100/100 - 1s - loss: 48824.2617 - mae: 74.4152 - val_loss: 1807339.7500 - val_mae: 711.5292\n",
      "Epoch 20/30\n",
      "100/100 - 1s - loss: 45856.2578 - mae: 72.0448 - val_loss: 1522653.6250 - val_mae: 658.2635\n",
      "Epoch 21/30\n",
      "100/100 - 1s - loss: 44535.6133 - mae: 70.2818 - val_loss: 1527045.6250 - val_mae: 658.6075\n",
      "Epoch 22/30\n",
      "100/100 - 1s - loss: 44051.3086 - mae: 70.8758 - val_loss: 2870445.2500 - val_mae: 1007.3994\n",
      "Epoch 23/30\n",
      "100/100 - 1s - loss: 45533.3086 - mae: 71.4563 - val_loss: 2474283.0000 - val_mae: 878.9059\n",
      "Epoch 24/30\n",
      "100/100 - 1s - loss: 42991.4844 - mae: 68.5432 - val_loss: 1364264.7500 - val_mae: 715.9927\n",
      "Epoch 25/30\n",
      "100/100 - 1s - loss: 44098.3477 - mae: 70.6596 - val_loss: 1469040.2500 - val_mae: 663.5047\n",
      "Epoch 26/30\n",
      "100/100 - 1s - loss: 43650.3086 - mae: 69.2371 - val_loss: 1360516.0000 - val_mae: 694.9548\n",
      "Epoch 27/30\n",
      "100/100 - 1s - loss: 41548.1875 - mae: 67.0575 - val_loss: 1274273.6250 - val_mae: 667.4829\n",
      "Epoch 28/30\n",
      "100/100 - 1s - loss: 42990.7188 - mae: 67.6480 - val_loss: 1471197.1250 - val_mae: 662.7128\n",
      "Epoch 29/30\n",
      "100/100 - 1s - loss: 43874.0859 - mae: 69.3174 - val_loss: 1378788.2500 - val_mae: 744.4696\n",
      "Epoch 30/30\n",
      "100/100 - 1s - loss: 42788.6797 - mae: 68.7763 - val_loss: 1260499.7500 - val_mae: 612.6343\n",
      "Epoch 1/30\n",
      "100/100 - 1s - loss: 43361.3398 - mae: 68.2983 - val_loss: 1963518.0000 - val_mae: 738.8719\n",
      "Epoch 2/30\n",
      "100/100 - 1s - loss: 49474.5078 - mae: 74.4379 - val_loss: 1678307.8750 - val_mae: 694.5085\n",
      "Epoch 3/30\n",
      "100/100 - 1s - loss: 48172.7891 - mae: 72.1741 - val_loss: 1490521.1250 - val_mae: 673.0367\n",
      "Epoch 4/30\n",
      "100/100 - 1s - loss: 42168.9570 - mae: 66.2877 - val_loss: 1328776.6250 - val_mae: 687.7205\n",
      "Epoch 5/30\n",
      "100/100 - 1s - loss: 41762.5586 - mae: 66.0102 - val_loss: 1538210.3750 - val_mae: 670.2983\n",
      "Epoch 6/30\n",
      "100/100 - 1s - loss: 42513.8047 - mae: 66.9943 - val_loss: 1611411.5000 - val_mae: 687.0372\n",
      "Epoch 7/30\n",
      "100/100 - 1s - loss: 40331.2148 - mae: 65.4504 - val_loss: 2443091.5000 - val_mae: 837.4800\n",
      "Epoch 8/30\n",
      "100/100 - 1s - loss: 41029.7812 - mae: 65.8217 - val_loss: 1554598.8750 - val_mae: 669.8210\n",
      "Epoch 9/30\n",
      "100/100 - 1s - loss: 40175.5938 - mae: 64.5969 - val_loss: 1480277.6250 - val_mae: 661.6239\n",
      "Epoch 10/30\n",
      "100/100 - 1s - loss: 40656.8789 - mae: 64.3894 - val_loss: 1623089.3750 - val_mae: 681.8204\n",
      "Epoch 11/30\n",
      "100/100 - 1s - loss: 40442.9453 - mae: 64.1539 - val_loss: 1724859.7500 - val_mae: 696.9023\n",
      "Epoch 12/30\n",
      "100/100 - 1s - loss: 39730.5234 - mae: 63.9605 - val_loss: 1872248.8750 - val_mae: 728.6272\n",
      "Epoch 13/30\n",
      "100/100 - 1s - loss: 42161.2852 - mae: 66.8818 - val_loss: 2164184.0000 - val_mae: 797.7900\n",
      "Epoch 14/30\n",
      "100/100 - 1s - loss: 40026.3828 - mae: 64.0200 - val_loss: 1290788.6250 - val_mae: 637.7195\n",
      "Epoch 15/30\n",
      "100/100 - 1s - loss: 41427.7656 - mae: 66.0722 - val_loss: 1340733.3750 - val_mae: 620.0319\n",
      "Epoch 16/30\n",
      "100/100 - 1s - loss: 39666.0898 - mae: 62.9129 - val_loss: 1975155.1250 - val_mae: 751.6519\n",
      "Epoch 17/30\n",
      "100/100 - 1s - loss: 40347.5391 - mae: 63.9576 - val_loss: 2116981.0000 - val_mae: 782.5373\n",
      "Epoch 18/30\n",
      "100/100 - 1s - loss: 42499.2695 - mae: 67.7566 - val_loss: 1919646.8750 - val_mae: 730.2507\n",
      "Epoch 19/30\n",
      "100/100 - 1s - loss: 42570.0312 - mae: 68.1791 - val_loss: 1453442.1250 - val_mae: 646.6566\n",
      "Epoch 20/30\n",
      "100/100 - 1s - loss: 40674.5742 - mae: 64.9130 - val_loss: 1428287.3750 - val_mae: 644.5673\n",
      "Epoch 21/30\n",
      "100/100 - 1s - loss: 40146.2695 - mae: 63.4386 - val_loss: 1640913.1250 - val_mae: 681.5013\n",
      "Epoch 22/30\n",
      "100/100 - 1s - loss: 40737.9023 - mae: 64.8637 - val_loss: 1771684.6250 - val_mae: 704.6497\n",
      "Epoch 23/30\n",
      "100/100 - 1s - loss: 40745.6875 - mae: 64.9688 - val_loss: 1491141.0000 - val_mae: 654.5737\n",
      "Epoch 24/30\n",
      "100/100 - 1s - loss: 40864.7773 - mae: 64.1709 - val_loss: 2605390.2500 - val_mae: 905.8856\n",
      "Epoch 25/30\n",
      "100/100 - 1s - loss: 40112.6953 - mae: 63.0517 - val_loss: 1493331.7500 - val_mae: 654.8208\n",
      "Epoch 26/30\n",
      "100/100 - 1s - loss: 40033.3789 - mae: 63.4325 - val_loss: 1368976.8750 - val_mae: 640.3877\n",
      "Epoch 27/30\n",
      "100/100 - 1s - loss: 39745.8164 - mae: 63.6883 - val_loss: 1323441.3750 - val_mae: 637.6310\n",
      "Epoch 28/30\n",
      "100/100 - 1s - loss: 40693.0664 - mae: 64.6554 - val_loss: 1632113.2500 - val_mae: 679.5628\n",
      "Epoch 29/30\n",
      "100/100 - 1s - loss: 39867.1445 - mae: 64.7315 - val_loss: 1246491.7500 - val_mae: 631.3149\n",
      "Epoch 30/30\n",
      "100/100 - 1s - loss: 41539.2383 - mae: 66.2659 - val_loss: 1381120.7500 - val_mae: 630.1317\n",
      "Epoch 1/30\n",
      "100/100 - 1s - loss: 42413.5508 - mae: 67.2083 - val_loss: 1310327.7500 - val_mae: 628.8777\n",
      "Epoch 2/30\n",
      "100/100 - 1s - loss: 41288.0156 - mae: 65.8597 - val_loss: 1292828.2500 - val_mae: 622.2659\n",
      "Epoch 3/30\n",
      "100/100 - 1s - loss: 41234.3047 - mae: 65.8444 - val_loss: 1213565.3750 - val_mae: 634.9176\n",
      "Epoch 4/30\n",
      "100/100 - 1s - loss: 40152.5273 - mae: 64.3729 - val_loss: 1363317.1250 - val_mae: 623.3817\n",
      "Epoch 5/30\n",
      "100/100 - 1s - loss: 39695.7266 - mae: 63.4382 - val_loss: 1904603.5000 - val_mae: 747.0490\n",
      "Epoch 6/30\n",
      "100/100 - 1s - loss: 40945.4570 - mae: 66.4939 - val_loss: 1622451.3750 - val_mae: 674.6558\n",
      "Epoch 7/30\n",
      "100/100 - 1s - loss: 40542.2031 - mae: 64.6075 - val_loss: 1323643.6250 - val_mae: 615.8945\n",
      "Epoch 8/30\n",
      "100/100 - 1s - loss: 39759.1328 - mae: 64.1767 - val_loss: 1281242.8750 - val_mae: 611.0322\n",
      "Epoch 9/30\n",
      "100/100 - 1s - loss: 39740.4727 - mae: 63.0934 - val_loss: 1518153.8750 - val_mae: 653.1833\n",
      "Epoch 10/30\n",
      "100/100 - 1s - loss: 40344.3867 - mae: 65.5447 - val_loss: 1247085.8750 - val_mae: 613.8106\n",
      "Epoch 11/30\n",
      "100/100 - 1s - loss: 39411.2930 - mae: 63.0669 - val_loss: 2011571.8750 - val_mae: 786.7875\n",
      "Epoch 12/30\n",
      "100/100 - 1s - loss: 39189.0078 - mae: 62.7546 - val_loss: 1449997.5000 - val_mae: 636.2287\n",
      "Epoch 13/30\n",
      "100/100 - 1s - loss: 38919.3594 - mae: 61.9207 - val_loss: 1842592.0000 - val_mae: 724.0532\n",
      "Epoch 14/30\n",
      "100/100 - 1s - loss: 39451.3945 - mae: 63.2043 - val_loss: 1307765.1250 - val_mae: 612.2668\n",
      "Epoch 15/30\n",
      "100/100 - 1s - loss: 40058.4844 - mae: 63.6832 - val_loss: 1380649.3750 - val_mae: 628.3022\n",
      "Epoch 16/30\n",
      "100/100 - 1s - loss: 40448.8203 - mae: 65.1116 - val_loss: 1490313.6250 - val_mae: 654.9001\n",
      "Epoch 17/30\n",
      "100/100 - 1s - loss: 39239.7461 - mae: 64.0746 - val_loss: 1280327.2500 - val_mae: 610.4420\n",
      "Epoch 18/30\n",
      "100/100 - 1s - loss: 39947.4492 - mae: 65.3833 - val_loss: 1173051.2500 - val_mae: 601.0786\n",
      "Epoch 19/30\n",
      "100/100 - 1s - loss: 40263.4805 - mae: 64.8267 - val_loss: 1438770.0000 - val_mae: 632.7901\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 - 1s - loss: 41190.6172 - mae: 65.6039 - val_loss: 1283499.1250 - val_mae: 606.2433\n",
      "Epoch 21/30\n",
      "100/100 - 1s - loss: 40926.6055 - mae: 66.0940 - val_loss: 1351365.0000 - val_mae: 619.4564\n",
      "Epoch 22/30\n",
      "100/100 - 1s - loss: 39155.5273 - mae: 63.0688 - val_loss: 1399986.0000 - val_mae: 627.1796\n",
      "Epoch 23/30\n",
      "100/100 - 1s - loss: 41918.8711 - mae: 67.5447 - val_loss: 1164637.2500 - val_mae: 610.9200\n",
      "Epoch 24/30\n",
      "100/100 - 1s - loss: 39736.6758 - mae: 64.3052 - val_loss: 1369563.5000 - val_mae: 621.5128\n",
      "Epoch 25/30\n",
      "100/100 - 1s - loss: 38873.8633 - mae: 62.7607 - val_loss: 1259853.5000 - val_mae: 602.6862\n",
      "Epoch 26/30\n",
      "100/100 - 1s - loss: 38438.6016 - mae: 61.9714 - val_loss: 1524210.2500 - val_mae: 668.8925\n",
      "Epoch 27/30\n",
      "100/100 - 1s - loss: 38974.1797 - mae: 62.9672 - val_loss: 1211449.2500 - val_mae: 593.7262\n",
      "Epoch 28/30\n",
      "100/100 - 1s - loss: 38783.3711 - mae: 62.6907 - val_loss: 1377638.3750 - val_mae: 621.4944\n",
      "Epoch 29/30\n",
      "100/100 - 1s - loss: 38238.1992 - mae: 61.1630 - val_loss: 1222597.2500 - val_mae: 593.6238\n",
      "Epoch 30/30\n",
      "100/100 - 1s - loss: 38770.0234 - mae: 63.0760 - val_loss: 1516849.1250 - val_mae: 666.0769\n",
      "Epoch 1/30\n",
      "100/100 - 1s - loss: 38612.0469 - mae: 62.5825 - val_loss: 1455951.6250 - val_mae: 653.2126\n",
      "Epoch 2/30\n",
      "100/100 - 1s - loss: 38262.8984 - mae: 61.7189 - val_loss: 1212505.5000 - val_mae: 590.4006\n",
      "Epoch 3/30\n",
      "100/100 - 1s - loss: 39779.7266 - mae: 65.3274 - val_loss: 1138704.7500 - val_mae: 610.0062\n",
      "Epoch 4/30\n",
      "100/100 - 1s - loss: 39126.5195 - mae: 63.0265 - val_loss: 1122778.2500 - val_mae: 584.3085\n",
      "Epoch 5/30\n",
      "100/100 - 1s - loss: 39242.0898 - mae: 64.4695 - val_loss: 1434796.6250 - val_mae: 639.1558\n",
      "Epoch 6/30\n",
      "100/100 - 1s - loss: 40081.0312 - mae: 65.1762 - val_loss: 1110704.3750 - val_mae: 578.9978\n",
      "Epoch 7/30\n",
      "100/100 - 1s - loss: 38402.2031 - mae: 62.5248 - val_loss: 1228996.3750 - val_mae: 591.1365\n",
      "Epoch 8/30\n",
      "100/100 - 1s - loss: 37859.6484 - mae: 60.9883 - val_loss: 1314909.5000 - val_mae: 607.8779\n",
      "Epoch 9/30\n",
      "100/100 - 1s - loss: 37654.6055 - mae: 60.9415 - val_loss: 1571637.7500 - val_mae: 679.9470\n",
      "Epoch 10/30\n",
      "100/100 - 1s - loss: 38160.5156 - mae: 61.9269 - val_loss: 1447995.5000 - val_mae: 647.7059\n",
      "Epoch 11/30\n",
      "100/100 - 1s - loss: 38890.3359 - mae: 63.3233 - val_loss: 1560003.7500 - val_mae: 681.9312\n",
      "Epoch 12/30\n",
      "100/100 - 1s - loss: 38520.6992 - mae: 62.4205 - val_loss: 1216595.8750 - val_mae: 591.7048\n",
      "Epoch 13/30\n",
      "100/100 - 1s - loss: 39090.0234 - mae: 63.0798 - val_loss: 1353485.7500 - val_mae: 624.3452\n",
      "Epoch 14/30\n",
      "100/100 - 1s - loss: 38032.2656 - mae: 61.5524 - val_loss: 1164603.0000 - val_mae: 579.4158\n",
      "Epoch 15/30\n",
      "100/100 - 1s - loss: 37497.1680 - mae: 60.6017 - val_loss: 1204017.3750 - val_mae: 589.2783\n",
      "Epoch 16/30\n",
      "100/100 - 1s - loss: 38215.7695 - mae: 61.7064 - val_loss: 2199435.7500 - val_mae: 857.9362\n",
      "Epoch 17/30\n",
      "100/100 - 1s - loss: 40289.1641 - mae: 65.3795 - val_loss: 1324075.0000 - val_mae: 620.3602\n",
      "Epoch 18/30\n",
      "100/100 - 1s - loss: 37942.2148 - mae: 61.2296 - val_loss: 1159623.5000 - val_mae: 578.9696\n",
      "Epoch 19/30\n",
      "100/100 - 1s - loss: 37912.3789 - mae: 61.3378 - val_loss: 1284895.8750 - val_mae: 603.6685\n",
      "Epoch 20/30\n",
      "100/100 - 1s - loss: 37478.6719 - mae: 61.1768 - val_loss: 1573544.3750 - val_mae: 685.2814\n",
      "Epoch 21/30\n",
      "100/100 - 1s - loss: 37001.5156 - mae: 60.0137 - val_loss: 1124503.8750 - val_mae: 572.7581\n",
      "Epoch 22/30\n",
      "100/100 - 1s - loss: 41282.9922 - mae: 68.1130 - val_loss: 1206083.7500 - val_mae: 585.6671\n",
      "Epoch 23/30\n",
      "100/100 - 1s - loss: 38366.9180 - mae: 62.0452 - val_loss: 1148768.1250 - val_mae: 576.4767\n",
      "Epoch 24/30\n",
      "100/100 - 1s - loss: 37479.0664 - mae: 60.3887 - val_loss: 1536540.2500 - val_mae: 673.9745\n",
      "Epoch 25/30\n",
      "100/100 - 1s - loss: 38103.0391 - mae: 61.9231 - val_loss: 1208712.2500 - val_mae: 585.9532\n",
      "Epoch 26/30\n",
      "100/100 - 1s - loss: 37797.2734 - mae: 61.0164 - val_loss: 1378915.0000 - val_mae: 627.8389\n",
      "Epoch 27/30\n",
      "100/100 - 1s - loss: 37396.0742 - mae: 60.4105 - val_loss: 1220345.5000 - val_mae: 589.8473\n",
      "Epoch 28/30\n",
      "100/100 - 1s - loss: 37731.2109 - mae: 60.7517 - val_loss: 1126011.7500 - val_mae: 576.0224\n",
      "Epoch 29/30\n",
      "100/100 - 1s - loss: 37143.4219 - mae: 59.9269 - val_loss: 1122329.2500 - val_mae: 570.9615\n",
      "Epoch 30/30\n",
      "100/100 - 1s - loss: 37338.4609 - mae: 60.4318 - val_loss: 1378613.3750 - val_mae: 636.3020\n",
      "Epoch 1/30\n",
      "100/100 - 1s - loss: 37480.1445 - mae: 60.5082 - val_loss: 1164184.8750 - val_mae: 579.3025\n",
      "Epoch 2/30\n",
      "100/100 - 1s - loss: 37232.2266 - mae: 60.6094 - val_loss: 1107302.0000 - val_mae: 570.1926\n",
      "Epoch 3/30\n",
      "100/100 - 1s - loss: 38086.4375 - mae: 61.9863 - val_loss: 1097905.3750 - val_mae: 566.1901\n",
      "Epoch 4/30\n",
      "100/100 - 1s - loss: 37950.8906 - mae: 61.9611 - val_loss: 1390457.8750 - val_mae: 635.9472\n",
      "Epoch 5/30\n",
      "100/100 - 1s - loss: 37311.0234 - mae: 60.8408 - val_loss: 1166063.3750 - val_mae: 579.6078\n",
      "Epoch 6/30\n",
      "100/100 - 1s - loss: 37449.8594 - mae: 60.9688 - val_loss: 1364513.1250 - val_mae: 637.3091\n",
      "Epoch 7/30\n",
      "100/100 - 1s - loss: 37283.4570 - mae: 60.5792 - val_loss: 1256118.8750 - val_mae: 604.4418\n",
      "Epoch 8/30\n",
      "100/100 - 1s - loss: 37637.4570 - mae: 61.0109 - val_loss: 1189993.2500 - val_mae: 583.0562\n",
      "Epoch 9/30\n",
      "100/100 - 1s - loss: 38111.5859 - mae: 61.7385 - val_loss: 1550894.2500 - val_mae: 685.5934\n",
      "Epoch 10/30\n",
      "100/100 - 1s - loss: 37672.4023 - mae: 61.0857 - val_loss: 1239028.1250 - val_mae: 595.9938\n",
      "Epoch 11/30\n",
      "100/100 - 1s - loss: 37706.9531 - mae: 61.0546 - val_loss: 1818746.6250 - val_mae: 758.1545\n",
      "Epoch 12/30\n",
      "100/100 - 1s - loss: 38629.5508 - mae: 62.8443 - val_loss: 1168643.1250 - val_mae: 579.5177\n",
      "Epoch 13/30\n",
      "100/100 - 1s - loss: 38986.0859 - mae: 62.3878 - val_loss: 1191558.8750 - val_mae: 588.9645\n",
      "Epoch 14/30\n",
      "100/100 - 1s - loss: 39592.9883 - mae: 64.2600 - val_loss: 1142076.1250 - val_mae: 576.2896\n",
      "Epoch 15/30\n",
      "100/100 - 1s - loss: 37115.8984 - mae: 60.5624 - val_loss: 1352173.3750 - val_mae: 630.0115\n",
      "Epoch 16/30\n",
      "100/100 - 1s - loss: 37624.2578 - mae: 61.2510 - val_loss: 1530024.8750 - val_mae: 678.2234\n",
      "Epoch 17/30\n",
      "100/100 - 1s - loss: 38649.8047 - mae: 62.3708 - val_loss: 1078470.1250 - val_mae: 580.3815\n",
      "Epoch 18/30\n",
      "100/100 - 1s - loss: 38888.5273 - mae: 63.0644 - val_loss: 1109385.8750 - val_mae: 566.3067\n",
      "Epoch 19/30\n",
      "100/100 - 1s - loss: 36956.1562 - mae: 60.0431 - val_loss: 1186995.0000 - val_mae: 581.3329\n",
      "Epoch 20/30\n",
      "100/100 - 1s - loss: 37237.8906 - mae: 60.3952 - val_loss: 1081923.0000 - val_mae: 568.8006\n",
      "Epoch 21/30\n",
      "100/100 - 1s - loss: 37870.6836 - mae: 61.9321 - val_loss: 1427770.3750 - val_mae: 647.4451\n",
      "Epoch 22/30\n",
      "100/100 - 1s - loss: 37515.9180 - mae: 60.8304 - val_loss: 1231580.1250 - val_mae: 592.4638\n",
      "Epoch 23/30\n",
      "100/100 - 1s - loss: 37372.6016 - mae: 60.3194 - val_loss: 1614555.1250 - val_mae: 703.1906\n",
      "Epoch 24/30\n",
      "100/100 - 1s - loss: 37167.4414 - mae: 60.0250 - val_loss: 1122014.2500 - val_mae: 569.5824\n",
      "Epoch 25/30\n",
      "100/100 - 1s - loss: 37677.4922 - mae: 60.8788 - val_loss: 1191494.6250 - val_mae: 582.9832\n",
      "Epoch 26/30\n",
      "100/100 - 1s - loss: 36994.1289 - mae: 59.6553 - val_loss: 1177753.7500 - val_mae: 579.7414\n",
      "Epoch 27/30\n",
      "100/100 - 1s - loss: 36844.6680 - mae: 59.2997 - val_loss: 1108508.3750 - val_mae: 562.8013\n",
      "Epoch 28/30\n",
      "100/100 - 1s - loss: 37697.3086 - mae: 61.3814 - val_loss: 1162241.6250 - val_mae: 576.1872\n",
      "Epoch 29/30\n",
      "100/100 - 1s - loss: 37751.3359 - mae: 61.4908 - val_loss: 1235646.5000 - val_mae: 594.5486\n",
      "Epoch 30/30\n",
      "100/100 - 1s - loss: 36825.0312 - mae: 59.4031 - val_loss: 1191356.6250 - val_mae: 582.3853\n",
      "Epoch 1/30\n",
      "100/100 - 1s - loss: 37313.2852 - mae: 60.5985 - val_loss: 1110299.7500 - val_mae: 564.7950\n",
      "Epoch 2/30\n",
      "100/100 - 1s - loss: 37194.6289 - mae: 60.3729 - val_loss: 1144035.8750 - val_mae: 572.3884\n",
      "Epoch 3/30\n",
      "100/100 - 1s - loss: 37170.1328 - mae: 60.1254 - val_loss: 1279040.7500 - val_mae: 605.3504\n",
      "Epoch 4/30\n",
      "100/100 - 1s - loss: 38777.0664 - mae: 62.9695 - val_loss: 1198709.6250 - val_mae: 585.9039\n",
      "Epoch 5/30\n",
      "100/100 - 1s - loss: 37515.2188 - mae: 60.3765 - val_loss: 1709437.1250 - val_mae: 735.4279\n",
      "Epoch 6/30\n",
      "100/100 - 1s - loss: 36642.6484 - mae: 59.0621 - val_loss: 1294989.7500 - val_mae: 611.0820\n",
      "Epoch 7/30\n",
      "100/100 - 1s - loss: 36573.5859 - mae: 59.1788 - val_loss: 1247066.0000 - val_mae: 596.2974\n",
      "Epoch 8/30\n",
      "100/100 - 1s - loss: 38032.0547 - mae: 61.4762 - val_loss: 1335075.1250 - val_mae: 624.0069\n",
      "Epoch 9/30\n",
      "100/100 - 1s - loss: 36989.8672 - mae: 59.9694 - val_loss: 1092690.0000 - val_mae: 566.6127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "100/100 - 1s - loss: 37642.3398 - mae: 60.6737 - val_loss: 1423319.1250 - val_mae: 647.9405\n",
      "Epoch 11/30\n",
      "100/100 - 1s - loss: 37122.5703 - mae: 59.7030 - val_loss: 1109398.2500 - val_mae: 571.3322\n",
      "Epoch 12/30\n",
      "100/100 - 1s - loss: 37310.7070 - mae: 60.5569 - val_loss: 1337016.7500 - val_mae: 622.0568\n",
      "Epoch 13/30\n",
      "100/100 - 1s - loss: 37128.3711 - mae: 60.5396 - val_loss: 1116180.2500 - val_mae: 567.8510\n",
      "Epoch 14/30\n",
      "100/100 - 1s - loss: 37481.7539 - mae: 60.7146 - val_loss: 1249949.5000 - val_mae: 599.1925\n",
      "Epoch 15/30\n",
      "100/100 - 1s - loss: 36820.5781 - mae: 59.4784 - val_loss: 1227394.2500 - val_mae: 593.4775\n",
      "Epoch 16/30\n",
      "100/100 - 1s - loss: 36592.3789 - mae: 58.8623 - val_loss: 1128852.2500 - val_mae: 570.3054\n",
      "Epoch 17/30\n",
      "100/100 - 1s - loss: 37128.3242 - mae: 59.7624 - val_loss: 1090907.8750 - val_mae: 593.2119\n",
      "Epoch 18/30\n",
      "100/100 - 1s - loss: 37350.4648 - mae: 60.5234 - val_loss: 1318325.5000 - val_mae: 614.7793\n",
      "Epoch 19/30\n",
      "100/100 - 1s - loss: 37079.5547 - mae: 60.1132 - val_loss: 1211919.6250 - val_mae: 587.5886\n",
      "Epoch 20/30\n",
      "100/100 - 1s - loss: 36618.7461 - mae: 59.0658 - val_loss: 1131455.8750 - val_mae: 568.9178\n",
      "Epoch 21/30\n",
      "100/100 - 1s - loss: 36624.8633 - mae: 58.7746 - val_loss: 1139187.3750 - val_mae: 570.2811\n",
      "Epoch 22/30\n",
      "100/100 - 1s - loss: 37198.4297 - mae: 59.7127 - val_loss: 1126524.3750 - val_mae: 568.9390\n",
      "Epoch 23/30\n",
      "100/100 - 1s - loss: 36718.1328 - mae: 59.2336 - val_loss: 1133498.2500 - val_mae: 569.3467\n",
      "Epoch 24/30\n",
      "100/100 - 1s - loss: 37140.1445 - mae: 60.1210 - val_loss: 1266449.5000 - val_mae: 604.9848\n",
      "Epoch 25/30\n",
      "100/100 - 1s - loss: 37284.3633 - mae: 60.3786 - val_loss: 1130425.1250 - val_mae: 569.4495\n",
      "Epoch 26/30\n",
      "100/100 - 1s - loss: 37485.0430 - mae: 61.0737 - val_loss: 1454301.7500 - val_mae: 657.7109\n",
      "Epoch 27/30\n",
      "100/100 - 1s - loss: 37525.5078 - mae: 61.5274 - val_loss: 1388403.5000 - val_mae: 635.5198\n",
      "Epoch 28/30\n",
      "100/100 - 1s - loss: 39414.6289 - mae: 63.2990 - val_loss: 1461817.2500 - val_mae: 669.5506\n",
      "Epoch 29/30\n",
      "100/100 - 1s - loss: 36996.6914 - mae: 60.4182 - val_loss: 1268598.7500 - val_mae: 605.8813\n",
      "Epoch 30/30\n",
      "100/100 - 1s - loss: 37192.9023 - mae: 60.2934 - val_loss: 1072301.2500 - val_mae: 564.9340\n",
      "Epoch 1/30\n",
      "100/100 - 1s - loss: 37381.6758 - mae: 60.8201 - val_loss: 1364863.2500 - val_mae: 641.3859\n",
      "Epoch 2/30\n",
      "100/100 - 1s - loss: 36986.0859 - mae: 60.1912 - val_loss: 1193541.1250 - val_mae: 588.1269\n",
      "Epoch 3/30\n",
      "100/100 - 1s - loss: 36742.7930 - mae: 59.2488 - val_loss: 1122518.5000 - val_mae: 569.1091\n",
      "Epoch 4/30\n",
      "100/100 - 1s - loss: 36567.9961 - mae: 58.8186 - val_loss: 1358455.7500 - val_mae: 633.7179\n",
      "Epoch 5/30\n",
      "100/100 - 1s - loss: 37163.2578 - mae: 59.9923 - val_loss: 1169256.8750 - val_mae: 579.7894\n",
      "Epoch 6/30\n",
      "100/100 - 1s - loss: 36804.2930 - mae: 59.7158 - val_loss: 1306632.2500 - val_mae: 614.5319\n",
      "Epoch 7/30\n",
      "100/100 - 1s - loss: 36521.4922 - mae: 59.2094 - val_loss: 1186030.8750 - val_mae: 584.3901\n",
      "Epoch 8/30\n",
      "100/100 - 1s - loss: 38366.5781 - mae: 62.2758 - val_loss: 1252600.6250 - val_mae: 601.4155\n",
      "Epoch 9/30\n",
      "100/100 - 1s - loss: 38614.7930 - mae: 62.3756 - val_loss: 1076192.7500 - val_mae: 566.2443\n",
      "Epoch 10/30\n",
      "100/100 - 1s - loss: 37034.2266 - mae: 60.0683 - val_loss: 1305181.6250 - val_mae: 618.5957\n",
      "Epoch 11/30\n",
      "100/100 - 1s - loss: 36825.5195 - mae: 59.4475 - val_loss: 1373820.6250 - val_mae: 640.4734\n",
      "Epoch 12/30\n",
      "100/100 - 1s - loss: 36658.1797 - mae: 59.1693 - val_loss: 1114592.7500 - val_mae: 571.3099\n",
      "Epoch 13/30\n",
      "100/100 - 1s - loss: 36498.6602 - mae: 58.6115 - val_loss: 1148826.3750 - val_mae: 574.9815\n",
      "Epoch 14/30\n",
      "100/100 - 1s - loss: 36597.7969 - mae: 58.9537 - val_loss: 1378886.6250 - val_mae: 640.3016\n",
      "Epoch 15/30\n",
      "100/100 - 1s - loss: 36855.9219 - mae: 59.4373 - val_loss: 1172556.8750 - val_mae: 581.5958\n",
      "Epoch 16/30\n",
      "100/100 - 1s - loss: 36334.7461 - mae: 58.6167 - val_loss: 1215011.7500 - val_mae: 590.4405\n",
      "Epoch 17/30\n",
      "100/100 - 1s - loss: 36807.3867 - mae: 59.4166 - val_loss: 1090787.8750 - val_mae: 566.6942\n",
      "Epoch 18/30\n",
      "100/100 - 1s - loss: 36693.7578 - mae: 59.2617 - val_loss: 1112985.1250 - val_mae: 566.7650\n",
      "Epoch 19/30\n",
      "100/100 - 1s - loss: 36849.5703 - mae: 59.5353 - val_loss: 1083257.8750 - val_mae: 566.2003\n",
      "Epoch 20/30\n",
      "100/100 - 1s - loss: 37644.6758 - mae: 61.5312 - val_loss: 1481828.6250 - val_mae: 661.6108\n",
      "Epoch 21/30\n",
      "100/100 - 1s - loss: 37706.5156 - mae: 61.1080 - val_loss: 1140493.2500 - val_mae: 589.3020\n",
      "Epoch 22/30\n",
      "100/100 - 1s - loss: 39206.3594 - mae: 63.7667 - val_loss: 1231489.5000 - val_mae: 593.0687\n",
      "Epoch 23/30\n",
      "100/100 - 1s - loss: 37385.7461 - mae: 60.4419 - val_loss: 1182680.6250 - val_mae: 581.5071\n",
      "Epoch 24/30\n",
      "100/100 - 1s - loss: 38191.7773 - mae: 61.8977 - val_loss: 1079040.8750 - val_mae: 565.9185\n",
      "Epoch 25/30\n",
      "100/100 - 1s - loss: 36791.8398 - mae: 59.2730 - val_loss: 1182059.8750 - val_mae: 581.1081\n",
      "Epoch 26/30\n",
      "100/100 - 1s - loss: 37753.1602 - mae: 61.1645 - val_loss: 1267531.2500 - val_mae: 602.7206\n",
      "Epoch 27/30\n",
      "100/100 - 1s - loss: 36655.6758 - mae: 59.0247 - val_loss: 1165996.5000 - val_mae: 576.2817\n",
      "Epoch 28/30\n",
      "100/100 - 1s - loss: 36836.3828 - mae: 59.5723 - val_loss: 1322335.7500 - val_mae: 618.2788\n",
      "Epoch 29/30\n",
      "100/100 - 1s - loss: 36416.2266 - mae: 58.7891 - val_loss: 1125912.1250 - val_mae: 568.2864\n",
      "Epoch 30/30\n",
      "100/100 - 1s - loss: 38545.2031 - mae: 62.2391 - val_loss: 1161146.5000 - val_mae: 576.7729\n",
      "Epoch 1/30\n",
      "100/100 - 1s - loss: 36562.9844 - mae: 59.1670 - val_loss: 1238755.0000 - val_mae: 594.4249\n",
      "Epoch 2/30\n",
      "100/100 - 1s - loss: 36412.2148 - mae: 58.8119 - val_loss: 1296363.1250 - val_mae: 610.2618\n",
      "Epoch 3/30\n",
      "100/100 - 1s - loss: 36412.3516 - mae: 58.7139 - val_loss: 1259220.0000 - val_mae: 601.7345\n",
      "Epoch 4/30\n",
      "100/100 - 1s - loss: 36492.9375 - mae: 58.9841 - val_loss: 1504139.0000 - val_mae: 674.6349\n",
      "Epoch 5/30\n",
      "100/100 - 1s - loss: 37405.5117 - mae: 60.6373 - val_loss: 1085445.6250 - val_mae: 584.4699\n",
      "Epoch 6/30\n",
      "100/100 - 1s - loss: 37096.1914 - mae: 59.9906 - val_loss: 1158876.0000 - val_mae: 575.3735\n",
      "Epoch 7/30\n",
      "100/100 - 1s - loss: 37885.5742 - mae: 61.9522 - val_loss: 1102591.1250 - val_mae: 567.0067\n",
      "Epoch 8/30\n",
      "100/100 - 1s - loss: 36775.4297 - mae: 59.2395 - val_loss: 1442450.0000 - val_mae: 654.4781\n",
      "Epoch 9/30\n",
      "100/100 - 1s - loss: 38052.6328 - mae: 62.6132 - val_loss: 1142929.6250 - val_mae: 574.8112\n",
      "Epoch 10/30\n",
      "100/100 - 1s - loss: 36931.1016 - mae: 60.4430 - val_loss: 1139521.2500 - val_mae: 571.5373\n",
      "Epoch 11/30\n",
      "100/100 - 1s - loss: 37059.9688 - mae: 59.7717 - val_loss: 1312680.1250 - val_mae: 620.8735\n",
      "Epoch 12/30\n",
      "100/100 - 1s - loss: 37362.7500 - mae: 60.4449 - val_loss: 1324236.5000 - val_mae: 619.6470\n",
      "Epoch 13/30\n",
      "100/100 - 1s - loss: 37029.2227 - mae: 60.5239 - val_loss: 1129667.6250 - val_mae: 569.5457\n",
      "Epoch 14/30\n",
      "100/100 - 1s - loss: 37499.7148 - mae: 61.1268 - val_loss: 1150092.2500 - val_mae: 576.0308\n",
      "Epoch 15/30\n",
      "100/100 - 1s - loss: 37112.9883 - mae: 60.3251 - val_loss: 1126647.3750 - val_mae: 567.4761\n",
      "Epoch 16/30\n",
      "100/100 - 1s - loss: 37451.5547 - mae: 60.6904 - val_loss: 1107704.7500 - val_mae: 563.9958\n",
      "Epoch 17/30\n",
      "100/100 - 1s - loss: 36619.2812 - mae: 58.8940 - val_loss: 1286034.0000 - val_mae: 613.1069\n",
      "Epoch 18/30\n",
      "100/100 - 1s - loss: 36936.4961 - mae: 59.8391 - val_loss: 1061093.2500 - val_mae: 562.8787\n",
      "Epoch 19/30\n",
      "100/100 - 1s - loss: 36820.4297 - mae: 60.6578 - val_loss: 1273065.0000 - val_mae: 606.9292\n",
      "Epoch 20/30\n",
      "100/100 - 1s - loss: 36620.9609 - mae: 59.0300 - val_loss: 1124877.0000 - val_mae: 571.6760\n",
      "Epoch 21/30\n",
      "100/100 - 1s - loss: 37614.0391 - mae: 61.5462 - val_loss: 1224239.6250 - val_mae: 646.5086\n",
      "Epoch 22/30\n",
      "100/100 - 1s - loss: 37365.8398 - mae: 61.2222 - val_loss: 1297309.1250 - val_mae: 613.8848\n",
      "Epoch 23/30\n",
      "100/100 - 1s - loss: 36928.4141 - mae: 59.7606 - val_loss: 1133801.2500 - val_mae: 566.5587\n",
      "Epoch 24/30\n",
      "100/100 - 1s - loss: 37158.1523 - mae: 60.3953 - val_loss: 1060562.8750 - val_mae: 557.8846\n",
      "Epoch 25/30\n",
      "100/100 - 1s - loss: 39688.9180 - mae: 64.5489 - val_loss: 1213727.5000 - val_mae: 586.9334\n",
      "Epoch 26/30\n",
      "100/100 - 1s - loss: 36515.0703 - mae: 58.9562 - val_loss: 1115269.2500 - val_mae: 562.5524\n",
      "Epoch 27/30\n",
      "100/100 - 1s - loss: 36454.8320 - mae: 58.5592 - val_loss: 1283283.5000 - val_mae: 611.7329\n",
      "Epoch 28/30\n",
      "100/100 - 1s - loss: 36279.9297 - mae: 58.5497 - val_loss: 1176052.5000 - val_mae: 580.4053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "100/100 - 1s - loss: 37333.9453 - mae: 60.4997 - val_loss: 1143342.8750 - val_mae: 571.4907\n",
      "Epoch 30/30\n",
      "100/100 - 1s - loss: 36673.2305 - mae: 59.3914 - val_loss: 1059830.1250 - val_mae: 559.5101\n",
      "19 s ± 170 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "res = nn_manager_cut.model_fit(n_epoch=30, n_seq=n_seq, n_steps=n_steps_subseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
