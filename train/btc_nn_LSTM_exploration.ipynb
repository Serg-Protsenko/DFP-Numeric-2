{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.set_visible_devices(physical_devices[0:1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-hv27kmny because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'cls_nnetwork' from './classes/cls_nnetwork.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, \"./classes/\")\n",
    "import cls_nnetwork\n",
    "\n",
    "# reloading functions without runtime.restart\n",
    "import importlib\n",
    "importlib.reload(cls_nnetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> train-test inited:  {'y_test': True, 'X_test': True, 'y_train': True, 'X_train': True}\n"
     ]
    }
   ],
   "source": [
    "# cut -- train test data with trimmed columns, so that it's more easy to train\n",
    "\n",
    "nn_manager_cut = cls_nnetwork.NeuralManager(dir_path='../data/csv_to_train/train_test_cut/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Vol', 'TOUTV', 'TRFEE', 'AVBLS', 'NTRAT',\n",
       "       'BTC_MINED_PDAY', 'VOL_CHANGE_PDAY', 'MWNUS_CH_PDAY', 'NTRAT_CH_PDAY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loaded\n",
    "\n",
    "nn_manager_cut.X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Vol', 'TOUTV', 'TRFEE', 'AVBLS', 'NTRAT',\n",
       "       'BTC_MINED_PDAY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_test.drop(columns=['VOL_CHANGE_PDAY', 'MWNUS_CH_PDAY', 'NTRAT_CH_PDAY'], inplace=True)\n",
    "nn_manager_cut.X_train.drop(columns=['VOL_CHANGE_PDAY', 'MWNUS_CH_PDAY', 'NTRAT_CH_PDAY'], inplace=True)\n",
    "nn_manager_cut.X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41241299, -0.41609214, -0.40874501, -0.73074627, -0.75910019,\n",
       "        -0.55514333, -0.33472626, -0.32963618,  2.38004535],\n",
       "       [-0.41224727, -0.41609214, -0.40874501, -0.72174512, -0.7634317 ,\n",
       "        -0.56252855, -0.33449781, -0.32963083,  0.96507937]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "nn_manager_cut.normalize_X(scaler=RobustScaler)\n",
    "\n",
    "nn_manager_cut.X_train_normalized[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolling data to sequences\n",
    "[[to #Model-fit]](#Model-fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting sequence len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.training_seq_params -->  {'seq_len': 2, 'n_features': 9}\n",
      "self.X_train_shape -->  [2, 9]\n",
      "self.X_test_shape -->  [2, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.set_train_test_data_shapes(shape_kwargs=dict(seq_len=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_manager_cut.unroll_train_test_to_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.0592476 , 15.35079893, 13.91339079,  4.16495982, -0.26722019,\n",
       "         0.38112094,  1.21426462,  2.26182627, -0.11609977],\n",
       "       [15.39103414, 15.6307892 , 14.39722514,  4.00551091, -0.11062799,\n",
       "         0.23478524,  1.11310196,  2.263432  , -0.21405896]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_test_unrolled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.39103414, 15.6307892 , 14.39722514,  4.00551091, -0.11062799,\n",
       "         0.23478524,  1.11310196,  2.263432  , -0.21405896],\n",
       "       [14.73293006, 14.96536621, 14.51662813,  3.66659013,  0.27703483,\n",
       "         0.88298001,  1.0297606 ,  2.26368224, -0.36462585]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# goes up by one sequence -- compare this cell result vs previous\n",
    "nn_manager_cut.X_test_unrolled[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(             Price\n",
       " Date              \n",
       " 2018-03-10  8762.0\n",
       " 2018-03-11  9529.6\n",
       " 2018-03-12  9137.4\n",
       " 2018-03-13  9154.9\n",
       " 2018-03-14  8210.6\n",
       " 2018-03-15  8264.4,\n",
       " array([[9137.4],\n",
       "        [9154.9],\n",
       "        [8210.6],\n",
       "        [8264.4],\n",
       "        [8289.2],\n",
       "        [7874.9]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on the base of the first two elements of the sequence we want to predict the third's day price\n",
    "\n",
    "nn_manager_cut.y_test.iloc[:6], nn_manager_cut.y_test_unrolled[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[n_seq-n_steps in MLM example elaboration](z_MlMastery%20LSTM%20for%20TS%20.ipynb#n_seq-n_steps)<br>\n",
    "(We can parameterize this and define the number of subsequences as n_seq and the number of time steps per subsequence as n_steps. [[source]](https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/#:~:text=We%20can%20parameterize%20this%20and))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    LeakyReLU,\n",
    "    TimeDistributed, \n",
    "    Conv1D, \n",
    "    MaxPooling1D, \n",
    "    Flatten, \n",
    "    LSTM, \n",
    "    Bidirectional,\n",
    "    Dense, \n",
    "    Dropout, \n",
    "    BatchNormalization)\n",
    "from tensorflow.keras.initializers import GlorotUniform, GlorotNormal\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM-based\n",
    "[[Unrolling Seq Len]](#Unrolling-data-to-sequences)<br>\n",
    "[[to #Model-fit]](#Model-fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_model_shape=(nn_manager_cut.training_seq_params['seq_len'], nn_manager_cut.training_seq_params['n_features'])\n",
    "input_model_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Architecture\n",
    "\n",
    "weights_init = GlorotNormal()\n",
    "\n",
    "template_Stacked_LSTM = [\n",
    "    Bidirectional(LSTM(100, \n",
    "                       activation=LeakyReLU(alpha=0.35), \n",
    "                       kernel_initializer=weights_init, \n",
    "                       return_sequences=True,\n",
    "                       # input_shape=input_model_shape             \n",
    "            ),\n",
    "         input_shape=input_model_shape),\n",
    "    Bidirectional(LSTM(100, \n",
    "                       activation=LeakyReLU(alpha=0.35), \n",
    "                       # input_shape=input_model_shape             \n",
    "            )),\n",
    "#     LSTM(30, activation=LeakyReLU(alpha=0.35), return_sequences=True,),    \n",
    "#     LSTM(30, activation=LeakyReLU(alpha=0.35)),    \n",
    "    Dense(10),\n",
    "    Dense(5),\n",
    "    Dense(1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2790, 2, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_train_unrolled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Model with the chosen Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> model compiled\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 2, 200)            88000     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 330,871\n",
      "Trainable params: 330,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assembling and compiling model\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "opt_adam = keras.optimizers.Adam(\n",
    "    learning_rate=1e-5, #wo BatchNorm\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False, \n",
    ")\n",
    "\n",
    "compile_dict = dict(optimizer=opt_adam, loss=keras.losses.Huber(delta=.5), metrics=['mae']) # huber loss as per outliers\n",
    "\n",
    "\n",
    "nn_manager_cut.model_combine(template=template_Stacked_LSTM, compile_dict=compile_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2790, 2, 9], [1194, 2, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_manager_cut.X_train_shape, nn_manager_cut.X_test_shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res = nn_manager_cut.model_fit(n_epoch=600,\n",
    "                           verbose=0, \n",
    "                           return_results=True, \n",
    "                           print_charts=True,\n",
    "                           early_stopping=True\n",
    "                        );\n",
    "plt.ylim(0,2e3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architectures: <br>\n",
    "[[#LSTM_Architecture]](#LSTM-based)\n",
    "\n",
    "Model Compiling setup [[go]](#Compiling-Model-with-the-chosen-Architecture)<br>\n",
    "Unrolling Seq Len [[go]](#Unrolling-data-to-sequences)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# nn_manager_cut.model.save(f'./saved_models/{datetime.now().strftime(\"%Y%m%d_%HH%MM%SS\")}_332_Bidi_2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whenloading, pay attention to sequence of days that was used to predict value\n",
    "\n",
    "# nn_manager_cut.model = keras.models.load_model('./saved_models/20210619_18H21M36S_363_Bidi/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filters=[\"Date<='2019.05.01'\"]\n",
    "# filters=[\"Date>='2020.07.10'\", \"Date<='2021.04.10'\"]\n",
    "\n",
    "# nn_manager_cut.plot_predicted_vs_test_price(filters=[\"Date>='2021.06.01'\"]) \n",
    "# nn_manager_cut.plot_predicted_vs_test_price(filters=[\"Date>='2020.11.10'\", \"Date<='2021.04.10'\"]) \n",
    "nn_manager_cut.plot_predicted_vs_test_price(filters=[\"Date>='2018.06.01'\", \"Date<='2018.06.15'\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start='2021.06.01'\n",
    "date_pred = '2021.06.03'\n",
    "nn_manager_cut.X_test.loc['2021.06.01':'2021.06.02'], \n",
    "# nn_manager_cut.y_test.loc[date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_pred = nn_manager_cut.scaler.transform(nn_manager_cut.X_test.loc['2018.06.08':'2018.06.09'])\n",
    "nn_manager_cut.model_predict(data_for_pred.reshape(1,\n",
    "                                                  nn_manager_cut.training_seq_params['seq_len'],\n",
    "                                                   nn_manager_cut.training_seq_params['n_features']))[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_manager_cut.y_test.loc['2018.06.10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion on LSTM Model:\n",
    "LSTM mdoel adds some inertia to the model, therefore this approach is not going to work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
